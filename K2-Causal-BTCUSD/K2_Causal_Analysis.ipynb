{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# K2 Algorithm for Causal Discovery in Financial Indicators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook shows a demo of how K2 algorithm can be used to discover causal relationships among financial indicators. We will use a synthetic dataset of financial indicators and apply the K2 algorithm to learn the structure of the causal graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "from scipy.stats import chi2_contingency\n",
        "import yfinance as yf\n",
        "from datetime import datetime, timedelta\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "class K2Algorithm:\n",
        "    \"\"\"\n",
        "    K2 Algorithm for Bayesian Network Structure Learning\n",
        "    \n",
        "    The K2 algorithm discovers causal relationships between variables by\n",
        "    constructing a Bayesian network structure. It greedily adds parents\n",
        "    to each node to maximize the Bayesian Dirichlet score.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    max_parents : int\n",
        "        Maximum number of parent nodes allowed for each variable\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, max_parents=3):\n",
        "        self.max_parents = max_parents\n",
        "        self.structure = {}\n",
        "        self.scores = {}\n",
        "        \n",
        "    def calculate_score(self, data, node, parents):\n",
        "        \"\"\"\n",
        "        Calculate the K2 score for a node given its parents\n",
        "        Uses Bayesian Dirichlet score\n",
        "        \"\"\"\n",
        "        if len(parents) == 0:\n",
        "            # No parents case\n",
        "            counts = data[node].value_counts()\n",
        "            n = len(data)\n",
        "            r = len(counts)\n",
        "            \n",
        "            score = 0\n",
        "            for count in counts.values:\n",
        "                score += self._log_factorial(count)\n",
        "            score -= self._log_factorial(n + r - 1)\n",
        "            score += self._log_factorial(r - 1)\n",
        "            \n",
        "            return score\n",
        "        \n",
        "        # With parents case\n",
        "        parent_cols = list(parents)\n",
        "        score = 0\n",
        "        parent_combinations = data[parent_cols].drop_duplicates()\n",
        "        \n",
        "        for _, parent_vals in parent_combinations.iterrows():\n",
        "            mask = True\n",
        "            for col in parent_cols:\n",
        "                mask &= (data[col] == parent_vals[col])\n",
        "            \n",
        "            subset = data[mask][node]\n",
        "            if len(subset) == 0:\n",
        "                continue\n",
        "                \n",
        "            counts = subset.value_counts()\n",
        "            n_ij = len(subset)\n",
        "            r = len(data[node].unique())\n",
        "            \n",
        "            for count in counts.values:\n",
        "                score += self._log_factorial(count)\n",
        "            score -= self._log_factorial(n_ij + r - 1)\n",
        "            score += self._log_factorial(r - 1)\n",
        "        \n",
        "        return score\n",
        "    \n",
        "    def _log_factorial(self, n):\n",
        "        \"\"\"Calculate log factorial efficiently\"\"\"\n",
        "        if n <= 1:\n",
        "            return 0\n",
        "        return np.sum(np.log(np.arange(1, n + 1)))\n",
        "    \n",
        "    def fit(self, data, node_order=None):\n",
        "        \"\"\"\n",
        "        Learn the Bayesian network structure using K2 algorithm\n",
        "        \n",
        "        Parameters:\n",
        "        -----------\n",
        "        data : DataFrame\n",
        "            Discretized variables\n",
        "        node_order : list, optional\n",
        "            Causal ordering of nodes\n",
        "        \"\"\"\n",
        "        if node_order is None:\n",
        "            node_order = list(data.columns)\n",
        "        \n",
        "        self.structure = {node: [] for node in node_order}\n",
        "        \n",
        "        for i, node in enumerate(node_order):\n",
        "            potential_parents = node_order[:i]\n",
        "            \n",
        "            if len(potential_parents) == 0:\n",
        "                continue\n",
        "            \n",
        "            current_parents = []\n",
        "            current_score = self.calculate_score(data, node, current_parents)\n",
        "            \n",
        "            improved = True\n",
        "            while improved and len(current_parents) < self.max_parents:\n",
        "                improved = False\n",
        "                best_score = current_score\n",
        "                best_parent = None\n",
        "                \n",
        "                for parent in potential_parents:\n",
        "                    if parent not in current_parents:\n",
        "                        test_parents = current_parents + [parent]\n",
        "                        test_score = self.calculate_score(data, node, test_parents)\n",
        "                        \n",
        "                        if test_score > best_score:\n",
        "                            best_score = test_score\n",
        "                            best_parent = parent\n",
        "                            improved = True\n",
        "                \n",
        "                if improved:\n",
        "                    current_parents.append(best_parent)\n",
        "                    current_score = best_score\n",
        "            \n",
        "            self.structure[node] = current_parents\n",
        "            self.scores[node] = current_score\n",
        "        \n",
        "        return self.structure\n",
        "    \n",
        "    def get_edges(self):\n",
        "        \"\"\"Return list of directed edges (parent -> child)\"\"\"\n",
        "        edges = []\n",
        "        for child, parents in self.structure.items():\n",
        "            for parent in parents:\n",
        "                edges.append((parent, child))\n",
        "        return edges\n",
        "    \n",
        "    def find_all_paths(self, start, end, path=[]):\n",
        "        \"\"\"Find all causal paths from start node to end node\"\"\"\n",
        "        path = path + [start]\n",
        "        if start == end:\n",
        "            return [path]\n",
        "        paths = []\n",
        "        for child, parents in self.structure.items():\n",
        "            if start in parents and child not in path:\n",
        "                newpaths = self.find_all_paths(child, end, path)\n",
        "                paths.extend(newpaths)\n",
        "        return paths\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will use BTCUSD, AAPL and GOLD data for the past 5 years to demonstrate the K2 algorithm for causal discovery. The K2 algorithm is a score-based method that identifies the most likely causal structure among a set of variables based on their observed data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fetch_market_data(ticker, start_date=None, end_date=None, period='1y'):\n",
        "    \"\"\"\n",
        "    Fetch market data from Yahoo Finance\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    ticker : str\n",
        "        Ticker symbol:\n",
        "        - 'BTC-USD' for Bitcoin\n",
        "        - 'GC=F' for Gold Futures\n",
        "        - 'AAPL' for Apple stock\n",
        "    start_date : str, optional\n",
        "        Start date in 'YYYY-MM-DD' format\n",
        "    end_date : str, optional\n",
        "        End date in 'YYYY-MM-DD' format\n",
        "    period : str\n",
        "        Period if dates not specified: '1mo', '3mo', '6mo', '1y', '2y', '5y'\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    df : DataFrame\n",
        "        DataFrame with Price column\n",
        "    \"\"\"\n",
        "    print(f\"Fetching data for {ticker}...\")\n",
        "    \n",
        "    try:\n",
        "        if start_date and end_date:\n",
        "            data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
        "        else:\n",
        "            data = yf.download(ticker, period=period, progress=False)\n",
        "        \n",
        "        if data.empty:\n",
        "            raise ValueError(f\"No data fetched for {ticker}\")\n",
        "        \n",
        "        # Handle recent yfinance update where data['Close'] might be a DataFrame (MultiIndex)\n",
        "        price_data = data['Close']\n",
        "        if isinstance(price_data, pd.DataFrame):\n",
        "            price_data = price_data.iloc[:, 0]\n",
        "            \n",
        "        df = pd.DataFrame({'Price': price_data})\n",
        "        df = df.dropna()\n",
        "        \n",
        "        print(f\"Fetched {len(df)} data points\")\n",
        "        print(f\"Date range: {df.index[0].strftime('%Y-%m-%d')} to {df.index[-1].strftime('%Y-%m-%d')}\")\n",
        "        print(f\"Price range: ${df['Price'].min():.2f} - ${df['Price'].max():.2f}\")\n",
        "        \n",
        "        return df\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching data: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_technical_indicators(df):\n",
        "    \"\"\"\n",
        "    Calculate comprehensive technical indicators\n",
        "    \n",
        "    Indicators:\n",
        "    - RSI (Relative Strength Index)\n",
        "    - EMA (Exponential Moving Averages)\n",
        "    - MACD (Moving Average Convergence Divergence)\n",
        "    - Bollinger Bands\n",
        "    - ATR (Average True Range)\n",
        "    - Magnitude % Move (target variable)\n",
        "    \"\"\"\n",
        "    \n",
        "    def calculate_rsi(prices, period=14):\n",
        "        delta = prices.diff()\n",
        "        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
        "        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
        "        rs = gain / loss\n",
        "        rsi = 100 - (100 / (1 + rs))\n",
        "        return rsi\n",
        "    \n",
        "    def calculate_ema(prices, period):\n",
        "        return prices.ewm(span=period, adjust=False).mean()\n",
        "    \n",
        "    def calculate_macd(prices, fast=12, slow=26, signal=9):\n",
        "        ema_fast = calculate_ema(prices, fast)\n",
        "        ema_slow = calculate_ema(prices, slow)\n",
        "        macd_line = ema_fast - ema_slow\n",
        "        signal_line = calculate_ema(macd_line, signal)\n",
        "        return macd_line, signal_line\n",
        "    \n",
        "    # Calculate indicators\n",
        "    df_ind = df.copy()\n",
        "    \n",
        "    df_ind['RSI_14'] = calculate_rsi(df_ind['Price'], 14)\n",
        "    df_ind['EMA_9'] = calculate_ema(df_ind['Price'], 9)\n",
        "    df_ind['EMA_20'] = calculate_ema(df_ind['Price'], 20)\n",
        "    \n",
        "    macd, signal = calculate_macd(df_ind['Price'])\n",
        "    df_ind['MACD'] = macd\n",
        "    df_ind['MACD_Signal'] = signal\n",
        "    df_ind['MACD_Hist'] = df_ind['MACD'] - df_ind['MACD_Signal']\n",
        "    \n",
        "    # Bollinger Bands\n",
        "    df_ind['BB_Middle'] = df_ind['Price'].rolling(window=20).mean()\n",
        "    df_ind['BB_Std'] = df_ind['Price'].rolling(window=20).std()\n",
        "    df_ind['BB_Upper'] = df_ind['BB_Middle'] + (df_ind['BB_Std'] * 2)\n",
        "    df_ind['BB_Lower'] = df_ind['BB_Middle'] - (df_ind['BB_Std'] * 2)\n",
        "    df_ind['BB_Width'] = (df_ind['BB_Upper'] - df_ind['BB_Lower']) / df_ind['BB_Middle']\n",
        "    \n",
        "    # ATR and Returns\n",
        "    df_ind['Returns'] = df_ind['Price'].pct_change()\n",
        "    df_ind['ATR'] = df_ind['Returns'].abs().rolling(window=14).mean() * 100\n",
        "    \n",
        "    # Target: Magnitude % move (5-period forward cumulative return)\n",
        "    df_ind['Magnitude_Move_%'] = df_ind['Returns'].rolling(window=5).sum() * 100\n",
        "    \n",
        "    return df_ind.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "K2 algorithm requires discrete variables. We'll convert continuous indicators into categorical bins."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def discretize_indicators(df, n_bins=5):\n",
        "    \"\"\"\n",
        "    Discretize continuous indicators into categorical bins\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : DataFrame\n",
        "        DataFrame with continuous indicators\n",
        "    n_bins : int\n",
        "        Number of bins (typically 3-5)\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    discretized : DataFrame\n",
        "        DataFrame with discretized indicators\n",
        "    \"\"\"\n",
        "    discretized = pd.DataFrame()\n",
        "    \n",
        "    indicators = ['RSI_14', 'EMA_9', 'EMA_20', 'MACD', 'MACD_Hist', \n",
        "                  'BB_Width', 'ATR', 'Magnitude_Move_%']\n",
        "    \n",
        "    if n_bins == 5:\n",
        "        labels = ['Very Low', 'Low', 'Medium', 'High', 'Very High']\n",
        "    elif n_bins == 3:\n",
        "        labels = ['Low', 'Medium', 'High']\n",
        "    else:\n",
        "        labels = [f'Bin_{i+1}' for i in range(n_bins)]\n",
        "    \n",
        "    for col in indicators:\n",
        "        if col in df.columns:\n",
        "            try:\n",
        "                discretized[col] = pd.qcut(df[col], q=n_bins, \n",
        "                                          labels=labels, \n",
        "                                          duplicates='drop')\n",
        "            except ValueError:\n",
        "                discretized[col] = pd.cut(df[col], bins=n_bins, \n",
        "                                         labels=labels)\n",
        "    \n",
        "    return discretized.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Statistical Analysis Functions\n",
        "\n",
        "Functions to validate and analyze discovered causal relationships."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_mutual_information(df, var1, var2):\n",
        "    \"\"\"\n",
        "    Calculate mutual information using Chi-square test\n",
        "    \"\"\"\n",
        "    crosstab = pd.crosstab(df[var1], df[var2])\n",
        "    chi2, p_value, dof, expected = chi2_contingency(crosstab)\n",
        "    n = len(df)\n",
        "    cramers_v = np.sqrt(chi2 / (n * (min(crosstab.shape) - 1)))\n",
        "    return chi2, p_value, cramers_v\n",
        "\n",
        "def analyze_conditional_probabilities(df, indicator, target):\n",
        "    \"\"\"\n",
        "    Analyze conditional probability P(target | indicator)\n",
        "    \"\"\"\n",
        "    crosstab = pd.crosstab(df[indicator], df[target], normalize='index') * 100\n",
        "    return crosstab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching data for BTC-USD...\n",
            "Fetched 1097 data points\n",
            "Date range: 2023-02-08 to 2026-02-08\n",
            "Price range: $20187.24 - $124752.53\n",
            "\n",
            "First 5 rows of Bitcoin data:\n",
            "                   Price\n",
            "Date                    \n",
            "2023-02-08  22939.398438\n",
            "2023-02-09  21819.039062\n",
            "2023-02-10  21651.183594\n",
            "2023-02-11  21870.875000\n",
            "2023-02-12  21788.203125\n"
          ]
        }
      ],
      "source": [
        "ticker = 'BTC-USD'\n",
        "asset_name = 'Bitcoin'\n",
        "\n",
        "df_raw = fetch_market_data(ticker, period='3y')  # Last 3 years\n",
        "\n",
        "print(f\"\\nFirst 5 rows of {asset_name} data:\")\n",
        "print(df_raw.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Calculated 14 indicators\n",
            "  Total data points: 1078\n",
            "\n",
            "Indicator Statistics:\n",
            "        RSI_14     MACD  MACD_Hist  BB_Width      ATR  Magnitude_Move_%\n",
            "count  1078.00  1078.00    1078.00   1078.00  1078.00           1078.00\n",
            "mean     53.17   403.45     -16.63      0.16     1.71              0.65\n",
            "std      17.29  1890.52     541.27      0.09     0.66              5.44\n",
            "min       6.60 -5927.45   -2261.49      0.03     0.45            -21.34\n",
            "25%      41.27  -667.08    -305.74      0.09     1.24             -2.32\n",
            "50%      51.83   250.92     -30.59      0.14     1.63              0.26\n",
            "75%      65.20  1319.73     287.09      0.19     2.03              3.46\n",
            "max      96.26  7049.22    1882.86      0.47     4.17             22.19\n",
            "\n",
            "Sample data with indicators:\n",
            "                   Price     RSI_14    MACD_Hist  Magnitude_Move_%\n",
            "Date                                                              \n",
            "2026-02-04  73019.703125  17.627890 -1630.056596        -13.752471\n",
            "2026-02-05  62702.097656  12.305688 -2261.493848        -21.335797\n",
            "2026-02-06  70555.390625  28.123784 -2011.086886         -6.716588\n",
            "2026-02-07  69281.968750  27.563531 -1798.945746        -10.748571\n",
            "2026-02-08  71408.664062  32.680862 -1400.821976         -3.796286\n"
          ]
        }
      ],
      "source": [
        "df_indicators = calculate_technical_indicators(df_raw)\n",
        "\n",
        "print(f\"\\nCalculated {len(df_indicators.columns)-1} indicators\")\n",
        "print(f\"  Total data points: {len(df_indicators)}\")\n",
        "\n",
        "print(\"\\nIndicator Statistics:\")\n",
        "indicators_to_show = ['RSI_14', 'MACD', 'MACD_Hist', 'BB_Width', 'ATR', 'Magnitude_Move_%']\n",
        "print(df_indicators[indicators_to_show].describe().round(2))\n",
        "\n",
        "print(\"\\nSample data with indicators:\")\n",
        "print(df_indicators[['Price', 'RSI_14', 'MACD_Hist', 'Magnitude_Move_%']].tail())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Discretized into 5 bins\n",
            "  Final dataset shape: (1078, 8)\n",
            "\n",
            "Distribution of Magnitude_Move_% bins:\n",
            "Magnitude_Move_%\n",
            "Very Low     216\n",
            "Low          215\n",
            "Medium       216\n",
            "High         215\n",
            "Very High    216\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Sample discretized data:\n",
            "              RSI_14     EMA_9    EMA_20    MACD MACD_Hist BB_Width  \\\n",
            "Date                                                                  \n",
            "2023-02-27      High  Very Low  Very Low  Medium    Medium     High   \n",
            "2023-02-28      High  Very Low  Very Low  Medium    Medium     High   \n",
            "2023-03-01       Low  Very Low  Very Low  Medium    Medium     High   \n",
            "2023-03-02    Medium  Very Low  Very Low  Medium    Medium     High   \n",
            "2023-03-03  Very Low  Very Low  Very Low  Medium       Low     High   \n",
            "2023-03-04  Very Low  Very Low  Very Low  Medium       Low   Medium   \n",
            "2023-03-05  Very Low  Very Low  Very Low     Low       Low   Medium   \n",
            "2023-03-06  Very Low  Very Low  Very Low     Low       Low   Medium   \n",
            "2023-03-07  Very Low  Very Low  Very Low     Low       Low   Medium   \n",
            "2023-03-08  Very Low  Very Low  Very Low     Low       Low     High   \n",
            "\n",
            "                  ATR Magnitude_Move_%  \n",
            "Date                                    \n",
            "2023-02-27  Very High              Low  \n",
            "2023-02-28  Very High         Very Low  \n",
            "2023-03-01     Medium             High  \n",
            "2023-03-02     Medium             High  \n",
            "2023-03-03     Medium         Very Low  \n",
            "2023-03-04     Medium         Very Low  \n",
            "2023-03-05        Low              Low  \n",
            "2023-03-06        Low         Very Low  \n",
            "2023-03-07        Low         Very Low  \n",
            "2023-03-08        Low              Low  \n"
          ]
        }
      ],
      "source": [
        "df_discrete = discretize_indicators(df_indicators, n_bins=5)\n",
        "\n",
        "print(f\"\\nDiscretized into 5 bins\")\n",
        "print(f\"  Final dataset shape: {df_discrete.shape}\")\n",
        "\n",
        "print(\"\\nDistribution of Magnitude_Move_% bins:\")\n",
        "print(df_discrete['Magnitude_Move_%'].value_counts().sort_index())\n",
        "\n",
        "print(\"\\nSample discretized data:\")\n",
        "print(df_discrete.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CAUSAL STRUCTURE DISCOVERY WITH K2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Node ordering (causal precedence):\n",
            "  1. RSI_14\n",
            "  2. EMA_9\n",
            "  3. EMA_20\n",
            "  4. MACD\n",
            "  5. MACD_Hist\n",
            "  6. BB_Width\n",
            "  7. ATR\n",
            "  8. Magnitude_Move_%\n",
            "\n",
            "Running K2 algorithm...\n",
            "\n",
            "Causal structure discovered!\n"
          ]
        }
      ],
      "source": [
        "# Define node ordering - CRITICAL for K2\n",
        "# Indicators come before target variable\n",
        "node_order = ['RSI_14', 'EMA_9', 'EMA_20', 'MACD', 'MACD_Hist', \n",
        "              'BB_Width', 'ATR', 'Magnitude_Move_%']\n",
        "\n",
        "print(f\"\\nNode ordering (causal precedence):\")\n",
        "for i, node in enumerate(node_order, 1):\n",
        "    print(f\"  {i}. {node}\")\n",
        "\n",
        "# Initialize and fit K2\n",
        "print(\"\\nRunning K2 algorithm...\")\n",
        "k2 = K2Algorithm(max_parents=3)\n",
        "structure = k2.fit(df_discrete[node_order], node_order=node_order)\n",
        "\n",
        "print(\"\\nCausal structure discovered!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Display Discovered Causal Relationships"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "RSI_14: No parents (root node)\n",
            "\n",
            "EMA_9: No parents (root node)\n",
            "\n",
            "EMA_20:\n",
            "  Direct causes (parents): EMA_9\n",
            "  Number of parents: 1\n",
            "  K2 Score: -333.90\n",
            "\n",
            "MACD:\n",
            "  Direct causes (parents): RSI_14, EMA_20\n",
            "  Number of parents: 2\n",
            "  K2 Score: -1306.50\n",
            "\n",
            "MACD_Hist:\n",
            "  Direct causes (parents): RSI_14, EMA_20\n",
            "  Number of parents: 2\n",
            "  K2 Score: -1343.79\n",
            "\n",
            "BB_Width:\n",
            "  Direct causes (parents): MACD, EMA_20, MACD_Hist\n",
            "  Number of parents: 3\n",
            "  K2 Score: -1414.77\n",
            "\n",
            "ATR:\n",
            "  Direct causes (parents): BB_Width, RSI_14, EMA_9\n",
            "  Number of parents: 3\n",
            "  K2 Score: -1449.70\n",
            "\n",
            "Magnitude_Move_%:\n",
            "  Direct causes (parents): MACD_Hist\n",
            "  Number of parents: 1\n",
            "  K2 Score: -1540.33\n",
            "\n",
            "======================================================================\n",
            "DIRECTED EDGES (Parent → Child)\n",
            "======================================================================\n",
            "  EMA_9 → EMA_20\n",
            "  RSI_14 → MACD\n",
            "  EMA_20 → MACD\n",
            "  RSI_14 → MACD_Hist\n",
            "  EMA_20 → MACD_Hist\n",
            "  MACD → BB_Width\n",
            "  EMA_20 → BB_Width\n",
            "  MACD_Hist → BB_Width\n",
            "  BB_Width → ATR\n",
            "  RSI_14 → ATR\n",
            "  EMA_9 → ATR\n",
            "  MACD_Hist → Magnitude_Move_%\n",
            "\n",
            "Total edges discovered: 12\n"
          ]
        }
      ],
      "source": [
        "for child, parents in structure.items():\n",
        "    if parents:\n",
        "        print(f\"\\n{child}:\")\n",
        "        print(f\"  Direct causes (parents): {', '.join(parents)}\")\n",
        "        print(f\"  Number of parents: {len(parents)}\")\n",
        "        print(f\"  K2 Score: {k2.scores[child]:.2f}\")\n",
        "    else:\n",
        "        print(f\"\\n{child}: No parents (root node)\")\n",
        "\n",
        "# Extract edges\n",
        "edges = k2.get_edges()\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DIRECTED EDGES (Parent → Child)\")\n",
        "print(\"=\"*70)\n",
        "for parent, child in edges:\n",
        "    print(f\"  {parent} → {child}\")\n",
        "\n",
        "print(f\"\\nTotal edges discovered: {len(edges)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Causal Paths to Target Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Discovered 4 causal paths:\n",
            "\n",
            "Path 1: RSI_14 → MACD_Hist → Magnitude_Move_%\n",
            "Path 2: EMA_9 → EMA_20 → MACD_Hist → Magnitude_Move_%\n",
            "Path 3: EMA_20 → MACD_Hist → Magnitude_Move_%\n",
            "Path 4: MACD_Hist → Magnitude_Move_%\n",
            "\n",
            "======================================================================\n",
            "KEY FINDING: DIRECT CAUSAL INDICATORS FOR MAGNITUDE MOVES\n",
            "======================================================================\n",
            "\n",
            "Direct causes of Magnitude_Move_%:\n",
            "  ==> MACD_Hist\n",
            "\n",
            "Indirect influences (through causal chains):\n",
            "  → EMA_20\n",
            "  → RSI_14\n",
            "  → EMA_9\n"
          ]
        }
      ],
      "source": [
        "target = 'Magnitude_Move_%'\n",
        "all_paths = []\n",
        "\n",
        "for node in structure.keys():\n",
        "    if node != target:\n",
        "        paths = k2.find_all_paths(node, target)\n",
        "        all_paths.extend(paths)\n",
        "\n",
        "print(f\"\\nDiscovered {len(all_paths)} causal paths:\\n\")\n",
        "for i, path in enumerate(all_paths, 1):\n",
        "    print(f\"Path {i}: {' → '.join(path)}\")\n",
        "\n",
        "# Direct causes\n",
        "direct_causes = structure[target]\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"KEY FINDING: DIRECT CAUSAL INDICATORS FOR MAGNITUDE MOVES\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nDirect causes of {target}:\")\n",
        "if direct_causes:\n",
        "    for cause in direct_causes:\n",
        "        print(f\"  ==> {cause}\")\n",
        "else:\n",
        "    print(\"  No direct causes found\")\n",
        "\n",
        "# Indirect causes\n",
        "print(f\"\\nIndirect influences (through causal chains):\")\n",
        "indirect = set()\n",
        "for path in all_paths:\n",
        "    if len(path) > 2:\n",
        "        indirect.add(path[0])\n",
        "\n",
        "for cause in indirect:\n",
        "    print(f\"  → {cause}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Statistical Validation\n",
        "\n",
        "Validate the discovered causal relationships using statistical tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Conditional Probability Analysis:\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "P(Magnitude_Move_% | MACD_Hist):\n",
            "\n",
            "Magnitude_Move_%  Very Low    Low  Medium   High  Very High\n",
            "MACD_Hist                                                  \n",
            "Very Low             53.24  21.76   14.35   8.33       2.31\n",
            "Low                  29.30  27.91   21.40  14.88       6.51\n",
            "Medium               12.04  29.17   24.54  22.69      11.57\n",
            "High                  5.12  16.74   23.26  26.98      27.91\n",
            "Very High             0.46   4.17   16.67  26.85      51.85\n",
            "\n",
            "(Values show percentage probabilities)\n"
          ]
        }
      ],
      "source": [
        "# Conditional probabilities for direct causes\n",
        "if direct_causes:\n",
        "    print(\"\\nConditional Probability Analysis:\")\n",
        "    print(\"-\" * 70)\n",
        "    \n",
        "    for cause in direct_causes:\n",
        "        print(f\"\\nP(Magnitude_Move_% | {cause}):\\n\")\n",
        "        cond_prob = analyze_conditional_probabilities(df_discrete, cause, target)\n",
        "        print(cond_prob.round(2))\n",
        "        print(\"\\n(Values show percentage probabilities)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Indicator  Chi-square      P-value  Cramers_V Significant Direct_Cause\n",
            "MACD_Hist  458.458341 1.905034e-87   0.326070         Yes          Yes\n",
            "   RSI_14  357.250151 3.180838e-66   0.287837         Yes           No\n",
            "     MACD  123.736159 1.047243e-18   0.169398         Yes           No\n",
            " BB_Width  108.745756 7.761857e-16   0.158806         Yes           No\n",
            "      ATR  100.883707 2.365059e-14   0.152958         Yes           No\n",
            "   EMA_20   52.656731 8.577403e-06   0.110506         Yes           No\n",
            "    EMA_9   44.870204 1.452967e-04   0.102009         Yes           No\n"
          ]
        }
      ],
      "source": [
        "# Chi-square test for all indicators\n",
        "indicators = ['RSI_14', 'EMA_9', 'EMA_20', 'MACD', 'MACD_Hist', 'BB_Width', 'ATR']\n",
        "\n",
        "results = []\n",
        "for indicator in indicators:\n",
        "    chi2, p_value, cramers_v = calculate_mutual_information(df_discrete, indicator, target)\n",
        "    results.append({\n",
        "        'Indicator': indicator,\n",
        "        'Chi-square': chi2,\n",
        "        'P-value': p_value,\n",
        "        'Cramers_V': cramers_v,\n",
        "        'Significant': 'Yes' if p_value < 0.05 else 'No',\n",
        "        'Direct_Cause': 'Yes' if indicator in structure[target] else 'No'\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results).sort_values('Chi-square', ascending=False)\n",
        "print(\"\\n\", results_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Network Adjacency Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Bayesian Network Structure (Adjacency Matrix):\n",
            "\n",
            "                   RSI_14  EMA_9  EMA_20  MACD  MACD_Hist  BB_Width  ATR  \\\n",
            "RSI_14                 0      0       0     1          1         0    1   \n",
            "EMA_9                  0      0       1     0          0         0    1   \n",
            "EMA_20                 0      0       0     1          1         1    0   \n",
            "MACD                   0      0       0     0          0         1    0   \n",
            "MACD_Hist              0      0       0     0          0         1    0   \n",
            "BB_Width               0      0       0     0          0         0    1   \n",
            "ATR                    0      0       0     0          0         0    0   \n",
            "Magnitude_Move_%       0      0       0     0          0         0    0   \n",
            "\n",
            "                  Magnitude_Move_%  \n",
            "RSI_14                           0  \n",
            "EMA_9                            0  \n",
            "EMA_20                           0  \n",
            "MACD                             0  \n",
            "MACD_Hist                        1  \n",
            "BB_Width                         0  \n",
            "ATR                              0  \n",
            "Magnitude_Move_%                 0  \n",
            "\n",
            "(1 = causal edge from row to column, 0 = no edge)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nBayesian Network Structure (Adjacency Matrix):\")\n",
        "\n",
        "nodes = node_order\n",
        "n = len(nodes)\n",
        "adj_matrix = np.zeros((n, n), dtype=int)\n",
        "\n",
        "node_to_idx = {node: i for i, node in enumerate(nodes)}\n",
        "\n",
        "for child, parents in structure.items():\n",
        "    child_idx = node_to_idx[child]\n",
        "    for parent in parents:\n",
        "        parent_idx = node_to_idx[parent]\n",
        "        adj_matrix[parent_idx, child_idx] = 1\n",
        "\n",
        "adj_df = pd.DataFrame(adj_matrix, index=nodes, columns=nodes)\n",
        "print(\"\\n\", adj_df)\n",
        "print(\"\\n(1 = causal edge from row to column, 0 = no edge)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How to interpret the results\n",
        "\n",
        "### 1. Identifying the \"Alpha\" Factors\n",
        "Look at the **\"Direct Causes of Magnitude_Move_%\"** section above.\n",
        "*   The indicators listed there are the **Primary Drivers**.\n",
        "*   **Action:** When building a trading strategy, these should be our main filter. The algorithm suggests these specific indicators have the most direct influence on price magnitude for this specific asset and timeframe.\n",
        "\n",
        "### 2. Deriving Trading Rules\n",
        "Look at the **\"Conditional Probability Analysis\"** table.\n",
        "*   This table converts the relationship into probabilities.\n",
        "*   **Example reading:** If `P(Magnitude_Move_% = High | RSI_14 = Low) > 50%`, it indicates a **Mean Reversion** tendency (Low RSI leading to High upward move).\n",
        "*   **Example reading:** If `P(Magnitude_Move_% = High | RSI_14 = High) > 50%`, it indicates a **Momentum** tendency (High RSI leading to continuation).\n",
        "\n",
        "### 3. Validating Signal Strength\n",
        "Look at the **\"Chi-square Test\"** table.\n",
        "*   **Cramér's V:** This represents the strength of the connection (0 to 1).\n",
        "    *   `V < 0.1`: Weak relationship (Noise).\n",
        "    *   `V > 0.15`: Moderate relationship (Useful).\n",
        "    *   `V > 0.3`: Strong relationship (High Predictive Power).\n",
        "*   **P-value:** If this is greater than 0.05, discard the indicator; the result is likely random chance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pythonGeneral",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
